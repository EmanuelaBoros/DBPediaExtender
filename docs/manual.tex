\documentclass[12pt]{article}

\usepackage{polski}
\usepackage[utf8]{inputenc}

\author{Marcin Zając\\Institute of Computer Science, Polish Academy of Sciences}
\title{DBPedia-extender manual}

\begin{document}
    \maketitle
    \section{About}
    The DBPediaExtender is an information extraction system that extends an existing ontology of geographical entities by extracting information from text. The system uses distant supervision – training data is constructed based on matches between values a knowledge base (taken from DBPedia) and Wikipedia articles.
    
    \section{Licensing}
    DBPediaExtender is released under the GNU General Public License v3.

    \section{Prerequisites}
    Software (versions tested):
    \begin{itemize}
        \item Python 2.6 or 2.7
        \item scikit-learn 0.11
        \item OpenLink Virtuoso (Open-Source Edition) 6.1.4
        \item crfsuite 0.12
        \item pantera-tagger 0.9
%        \item (optionally) spejd 1.3.6
%        \item (optionally) maltparser 1.7.1
%        \item (optionally) NTLK 2 and Polish Wordnet 1.5
    \end{itemize}
    Data:
    \begin{itemize}
        \item DBPedia dumps
        \item Wikipedia dumps
    \end{itemize}
    
    \section{Installation}
    DBPedia-extender is a pure python system, therefore it doesn't require any installation.
    However it relies on availability of two resources: a DBPedia server and Wikipedia articles.
    \subsection{DBPedia}
    The program queries a given DBPedia server endpoint over http. It can use any endpoint, however in practice, it is necessary to create a local DBPedia server.\\
    The process of installing and configuring the server is well described at apohllo.pl/blog/virtuoso-installation-in-debian.\\
    The Polish DBPedia dumps are not available at the Polish DBPedia website (pl.dbpedia.org). However, the Polish DBPedia maintainer (the Knowledge Hives – knowledgehives.com) is willing to give access to the data.\\
    \subsection{Wikipedia}
    When run for the first time the program will download the pages-articles archive and then extract articles from it. This task may take even a few hours.
    \section{Usage}
    ./dbpedia-enricher\\
    The src/ directory contains a configuration file (config.py), in which the user can set:
    \begin{itemize}
        \item verbosity level,
        \item which predicates to learn,
        \item program mode (explained below).
    \end{itemize}
    The program can run in two modes:
    \begin{itemize}
        \item Extraction (default) - the program trains on available data and generates a list of RDF triples that can be imported into DBPedia.\\ The triples extracted are stored in the results/ directory.
        \item Evaluation - the program trains on available data and then using manually annotated data, evaluates its performance. \\Program is distributed with manually annotated data for several predicates (in the tests/ directory).
    \end{itemize}
    
    \section{Results}
    The system is distributed with text files containing RDF triples generated by running the program on several relations using the Polish DBPedia and Wikipedia.
\end{document}


